{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4653379,"sourceType":"datasetVersion","datasetId":2703147}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cài đặt các thư viện cần thiết \n!pip install --upgrade transformers datasets jiwer librosa evaluate matplotlib\n!pip install -U ipywidgets","metadata":{"_uuid":"34735e7a-5b6e-4b43-a262-546fb4ee1267","_cell_guid":"a17475d8-6169-42e9-a923-a7a44769ceb6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import các thư viện\nimport os\nimport pandas as pd\nimport numpy as np\nimport librosa\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport wave\nimport contextlib\nimport torch\nimport torchaudio\nfrom torch.utils.data import DataLoader\nfrom tqdm.notebook import tqdm\nimport shutil\nimport re\nimport random\nimport json\nimport evaluate  # Thay thế load_metric bằng evaluate\nfrom datasets import load_dataset, Audio, Dataset\nfrom transformers import (Wav2Vec2ForCTC, Wav2Vec2Processor, Trainer, TrainingArguments,\n                          Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor, DataCollatorWithPadding)\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Union\n%matplotlib inline","metadata":{"_uuid":"8334062f-2998-46fd-913f-616c102b392f","_cell_guid":"a0e22073-3eb6-4c4a-b4a5-8f650b413a93","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Đặt seed\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Kiểm tra thiết bị\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Sử dụng thiết bị: {device}\")\n\n# Đường dẫn đến dataset VIVOS\ntrain_audio_path = '../input/vivos-vietnamese-speech-corpus-for-asr/vivos/train/waves'\ntrain_prompts_path = '../input/vivos-vietnamese-speech-corpus-for-asr/vivos/train/prompts.txt'\ntrain_genders_path = '../input/vivos-vietnamese-speech-corpus-for-asr/vivos/train/genders.txt'\n\ntest_audio_path = '../input/vivos-vietnamese-speech-corpus-for-asr/vivos/test/waves'\ntest_prompts_path = '../input/vivos-vietnamese-speech-corpus-for-asr/vivos/test/prompts.txt'\ntest_genders_path = '../input/vivos-vietnamese-speech-corpus-for-asr/vivos/test/genders.txt'","metadata":{"_uuid":"30349767-af79-45a9-9912-c2fd0c9d462b","_cell_guid":"fbecfafa-fe40-47f9-915e-c18c30180697","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hàm để đọc file prompts.txt và trả về DataFrame\ndef load_prompts(prompts_path):\n    transcripts = []\n    with open(prompts_path, 'r', encoding='utf-8') as f:\n        for line in f:\n            id, text = line.strip().split(' ', 1)\n            transcripts.append({'id': id, 'text': text.lower()})\n    return pd.DataFrame(transcripts)\n\n# Tạo DataFrame cho tập train và test\ntrain_transcripts = load_prompts(train_prompts_path)\ntest_transcripts = load_prompts(test_prompts_path)","metadata":{"_uuid":"ae4d2fcf-3388-4256-90df-0726eca404df","_cell_guid":"a2c05de0-06bc-4f47-b7ac-39353648ddde","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Thêm đường dẫn âm thanh vào DataFrame\ndef get_audio_path(audio_base_path, audio_id):\n    speaker = audio_id.split('_')[0]\n    return os.path.join(audio_base_path, speaker, audio_id + '.wav')\n\ntrain_transcripts['audio'] = train_transcripts['id'].apply(lambda x: get_audio_path(train_audio_path, x))\ntest_transcripts['audio'] = test_transcripts['id'].apply(lambda x: get_audio_path(test_audio_path, x))","metadata":{"_uuid":"5be8d721-f696-4243-adca-2f5d8f2eb93d","_cell_guid":"e2349a94-7116-4766-ac94-df0773d011d5","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loại bỏ các ký tự đặc biệt và chuyển văn bản về chữ thường\nchars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"“%‘”�]'\n\ndef remove_special_characters(batch):\n    batch[\"text\"] = re.sub(chars_to_ignore_regex, '', batch[\"text\"]).lower()\n    return batch\n\n# Áp dụng hàm tiền xử lý dữ liệu\ntrain_transcripts = train_transcripts.apply(remove_special_characters, axis=1)\ntest_transcripts = test_transcripts.apply(remove_special_characters, axis=1)","metadata":{"_uuid":"40f3ab0b-ae6e-4bad-973a-66b1bca8cfa7","_cell_guid":"60a2aded-ba42-4239-a358-17ddc7033792","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# vocab_dict = {\"ẻ\": 0, \"ẵ\": 1, \"k\": 2, \"ặ\": 3, \"d\": 4, \"õ\": 5, \"á\": 6, \"ở\": 7, \"s\": 8, \"ả\": 9, \"u\": 10, \"ừ\": 11, \"ử\": 12, \"ạ\": 13, \"ổ\": 14, \"â\": 15, \"ệ\": 16, \"ủ\": 17, \"ầ\": 18, \"e\": 19, \"ẳ\": 20, \"ỡ\": 21, \"v\": 22, \"ú\": 23, \"à\": 24, \"ù\": 25, \"m\": 26, \"ờ\": 27, \"ớ\": 28, \"ỵ\": 29, \"ắ\": 30, \"ấ\": 31, \"ó\": 32, \"y\": 33, \"ỏ\": 34, \"ỳ\": 35, \"ỷ\": 36, \"ê\": 37, \"ĩ\": 38, \"ậ\": 39, \"ợ\": 40, \"l\": 41, \"ố\": 42, \"ữ\": 43, \"ỗ\": 44, \"h\": 45, \"ẹ\": 46, \"ò\": 47, \"ộ\": 48, \"è\": 49, \"ơ\": 50, \"ồ\": 51, \"é\": 52, \"ế\": 53, \"ự\": 54, \"ô\": 55, \"c\": 56, \"n\": 57, \"ẽ\": 58, \"ă\": 59, \"ũ\": 60, \"ứ\": 61, \"ọ\": 62, \"ụ\": 63, \"ể\": 64, \"t\": 65, \"q\": 66, \"ý\": 67, \"í\": 68, \"ẩ\": 69, \"ề\": 70, \"ỉ\": 71, \"ư\": 72, \"r\": 73, \"ỹ\": 74, \"ị\": 75, \"ì\": 76, \"ằ\": 77, \"ã\": 78, \"đ\": 79, \"a\": 80, \"g\": 81, \"ễ\": 82, \"i\": 83, \"x\": 84, \"ẫ\": 85, \"b\": 87, \"o\": 88, \"p\": 89, \"|\": 86, \"[UNK]\": 90, \"[PAD]\": 91}","metadata":{"_uuid":"8a73ab93-1d0f-41c1-beb4-fc871b8bd955","_cell_guid":"ee5cb73b-bb93-47bb-8b93-8492cde6e649","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Lưu vocabulary thành file JSON\n# import json\n\n# with open('vocab.json', 'w', encoding='utf-8') as vocab_file:\n#     json.dump(vocab_dict, vocab_file, ensure_ascii=False)\n\n# # Khởi tạo tokenizer\n# vi_tokenizer = Wav2Vec2CTCTokenizer(\"vocab.json\", \n#                                  unk_token=\"[UNK]\", \n#                                  pad_token=\"[PAD]\", \n#                                  word_delimiter_token=\"|\")","metadata":{"_uuid":"862841a0-30ea-4a81-bf06-e9d0bfee28f9","_cell_guid":"26272f08-9473-4926-8f59-116b4f6e902e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tải processor và model từ mô hình pre-trained\n\nprocessor = Wav2Vec2Processor.from_pretrained(\"nguyenvulebinh/wav2vec2-base-vietnamese-250h\")\n\nmodel = Wav2Vec2ForCTC.from_pretrained(\"nguyenvulebinh/wav2vec2-base-vietnamese-250h\", \n                                       attention_dropout=0.15,       # Tăng dropout đế giảm overfitting\n                                       hidden_dropout=0.15, activation_dropout=0.15,\n                                       ctc_loss_reduction=\"mean\",\n                                       pad_token_id = processor.tokenizer.pad_token_id)","metadata":{"_uuid":"bfcf5147-5404-4fad-b210-43473151a23d","_cell_guid":"61b00de9-7c2f-4274-b13d-ac12c1d96241","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Chuyển đổi DataFrame thành Dataset của Hugging Face\ntrain_dataset = Dataset.from_pandas(train_transcripts)\ntest_dataset = Dataset.from_pandas(test_transcripts)\n\n# Chuyển cột 'audio' thành kiểu Audio\ntrain_dataset = train_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\ntest_dataset = test_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))","metadata":{"_uuid":"46f32165-113e-4465-b383-a57ee35e6684","_cell_guid":"61cf3fcb-a0b5-48e9-a691-672a5783f5db","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hàm tiền xử lý dữ liệu\ndef prepare_dataset(batch):\n    # Xử lý âm thanh\n    audio = batch[\"audio\"]\n    batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n    # Xử lý văn bản\n    batch[\"labels\"] = processor.tokenizer(batch[\"text\"]).input_ids\n    return batch\n\n# Áp dụng hàm tiền xử lý dữ liệu\ntrain_dataset = train_dataset.map(prepare_dataset, remove_columns=train_dataset.column_names)\ntest_dataset = test_dataset.map(prepare_dataset, remove_columns=test_dataset.column_names)","metadata":{"_uuid":"cde2ed9c-27bd-4970-8f74-6b414730e358","_cell_guid":"a4be8f5e-e1e3-4f9f-924d-4f58a985ccd7","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@dataclass\nclass DataCollatorCTCWithPadding:\n    processor: Wav2Vec2Processor\n    padding: Union[bool, str] = True\n\n    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:\n        # Tách inputs và labels\n        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n\n        # Padding inputs\n        batch = self.processor.feature_extractor.pad(\n            input_features,\n            padding=self.padding,\n            return_tensors=\"pt\",\n        )\n\n        # Padding labels\n        with self.processor.as_target_processor():\n            labels_batch = self.processor.pad(\n                label_features,\n                padding=self.padding,\n                return_tensors=\"pt\",\n            )\n\n        # Thay thế giá trị padding bằng -100\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch[\"attention_mask\"].ne(1), -100)\n\n        batch[\"labels\"] = labels\n\n        return batch\n\ndata_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)","metadata":{"_uuid":"cf467bbd-f150-47b4-84ce-dda34cc10156","_cell_guid":"876e3c5c-b4e3-4ff2-b1ae-773827dd38a9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Định nghĩa hàm tính WER\nwer_metric = evaluate.load(\"wer\")\n\ndef compute_metrics(pred):\n    pred_logits = pred.predictions\n    pred_ids = np.argmax(pred_logits, axis=-1)\n\n    # Giải mã dự đoán\n    pred_str = processor.batch_decode(pred_ids)\n\n    # Giải mã nhãn\n    label_ids = pred.label_ids\n    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n    label_str = processor.batch_decode(label_ids, group_tokens=False)\n\n    # Tính WER\n    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n    return {\"wer\": wer}","metadata":{"_uuid":"f53650e4-106e-4190-8c57-a261cd220db3","_cell_guid":"464acc3f-30d4-48ba-9861-6f1dfc01b420","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyTrainer:\n    def __init__(self, \n                 model=None, \n                 train_dataset=None,\n                 eval_dataset=None,\n                 processor=None,\n                 data_collator=None, \n                 learning_rate=1e-3,\n                 weight_decay=0.01,\n                 num_train_epochs=None, \n                 train_batch_size=None, \n                 gradient_accumulation_steps=1,\n                 save_steps=500,  \n                 logging_steps=500, \n                 warmup_steps=500,\n                 save_dir=\"./wav2vec2-vivos/checkpoints\",\n                 resume_from_checkpoint=False,\n                 checkpoint_dir=None,\n                 seed=42):  # Thêm tham số seed\n        \n        self.model = model\n        self.train_dataset = train_dataset\n        self.eval_dataset = eval_dataset\n        self.processor = processor\n        self.data_collator = data_collator\n        self.learning_rate = learning_rate\n        self.weight_decay = weight_decay\n        self.num_train_epochs = num_train_epochs\n        self.train_batch_size = train_batch_size\n        self.gradient_accumulation_steps = gradient_accumulation_steps\n        self.save_steps = save_steps\n        self.logging_steps = logging_steps\n        self.warmup_steps = warmup_steps\n        self.save_dir = save_dir\n        self.checkpoint_dir = checkpoint_dir  \n        self.resume_from_checkpoint = resume_from_checkpoint\n        self.seed = seed  # Lưu trữ seed\n        self.train_losses = []\n        self.eval_losses = []\n        self.eval_wers = []\n        self.train_eval_losses = []\n        self.train_eval_wers = []\n        self.learning_rate_values = []\n\n        # Đặt seed\n        random.seed(self.seed)\n        np.random.seed(self.seed)\n        torch.manual_seed(self.seed)\n        if torch.cuda.is_available():\n            torch.cuda.manual_seed(self.seed)\n            torch.cuda.manual_seed_all(self.seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.model.to(self.device)\n\n        # Optimizer\n        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n\n        self.start_epoch = 0\n        self.global_step = 0\n        if self.resume_from_checkpoint:\n            self.load_checkpoint()\n        else:\n            # Tính total_steps\n            self.total_steps = len(self.train_dataset) // (self.train_batch_size * self.gradient_accumulation_steps) * self.num_train_epochs\n            self.scheduler = torch.optim.lr_scheduler.OneCycleLR(\n                self.optimizer, \n                max_lr=self.learning_rate, \n                total_steps=self.total_steps, \n                pct_start=self.warmup_steps / self.total_steps\n            )\n                \n    def train(self):\n        generator = torch.Generator()\n        generator.manual_seed(self.seed)\n\n        trainer_loader = DataLoader(\n            self.train_dataset, \n            batch_size=self.train_batch_size, \n            collate_fn=self.data_collator, \n            shuffle=True,\n            generator=generator\n        )\n\n        for epoch in range(self.start_epoch, self.num_train_epochs):\n            self.model.train()\n            progress_bar = tqdm(trainer_loader, desc=f\"Epoch {epoch + 1}/{self.num_train_epochs}\", leave=False)\n            epoch_losses = []\n            for step, batch in enumerate(progress_bar):\n                inputs = batch['input_values'].to(self.device)\n                labels = batch['labels'].to(self.device)\n                \n                outputs = self.model(inputs, labels=labels)\n                loss = outputs.loss\n                loss = loss / self.gradient_accumulation_steps\n                loss.backward()\n\n                if (step + 1) % self.gradient_accumulation_steps == 0:\n                    self.optimizer.step()\n                    self.scheduler.step()\n                    self.optimizer.zero_grad()\n                    self.global_step += 1\n\n                    if self.global_step % self.logging_steps == 0:\n                        progress_bar.set_postfix(loss=loss.item())\n\n                    if self.global_step % self.save_steps == 0:\n                        eval_loss, eval_wer = self.evaluate()\n                        self.save_checkpoint(epoch, loss.item(), eval_loss, eval_wer)\n                epoch_losses.append(loss.item())\n                        \n            # Tính loss trung bình cho epoch\n            avg_train_loss = np.mean(epoch_losses)\n            self.train_losses.append(avg_train_loss)\n\n            # Đánh giá trên tập kiểm tra\n            eval_loss, eval_wer = self.evaluate()\n            self.eval_losses.append(eval_loss)\n            self.eval_wers.append(eval_wer)\n\n            # Đánh giá trên tập huấn luyện (tùy chọn, có thể bỏ qua nếu tập huấn luyện lớn)\n            train_eval_loss, train_eval_wer = self.evaluate(self.train_dataset, description=\"Evaluating on Train Dataset\")\n            self.train_eval_losses.append(train_eval_loss)\n            self.train_eval_wers.append(train_eval_wer)\n\n            self.learning_rate_values.append(self.scheduler.get_last_lr()[0])\n\n            self.save_checkpoint(epoch + 1, avg_train_loss, eval_loss, eval_wer)\n                \n    def evaluate(self, dataset=None, description=\"Evaluating\"):\n        if dataset is None:\n            dataset = self.eval_dataset\n        self.model.eval()\n        eval_loader = DataLoader(dataset, batch_size=1, collate_fn=self.data_collator)\n        losses = []\n        predictions = []\n        references = []\n\n        for batch in tqdm(eval_loader, desc=description, leave=False):\n            inputs = batch['input_values'].to(self.device)\n            labels = batch['labels'].to(self.device)\n            with torch.no_grad():\n                outputs = self.model(inputs, labels=labels)\n            loss = outputs.loss.item()\n            losses.append(loss)\n\n            # Lấy dự đoán\n            logits = outputs.logits\n            pred_ids = torch.argmax(logits, dim=-1)\n            pred_str = self.processor.batch_decode(pred_ids)\n            \n            # Lấy nhãn thực\n            label_ids = labels.cpu().numpy()\n            label_ids[label_ids == -100] = self.processor.tokenizer.pad_token_id\n            label_str = self.processor.batch_decode(label_ids, group_tokens=False)\n            \n            predictions.extend(pred_str)\n            references.extend(label_str)\n\n        avg_loss = np.mean(losses)\n        wer = wer_metric.compute(predictions=predictions, references=references)\n        self.model.train()\n        return avg_loss, wer\n\n    def save_checkpoint(self, epoch, train_loss, eval_loss, eval_wer):\n        os.makedirs(self.save_dir, exist_ok=True)\n        for item in os.listdir(self.save_dir):\n            item_path = os.path.join(self.save_dir, item)\n            if os.path.isfile(item_path):\n                os.remove(item_path)\n            elif os.path.isdir(item_path):\n                shutil.rmtree(item_path)\n        checkpoint_path = os.path.join(self.save_dir, f\"checkpoint_epoch_{epoch}.pth\")\n        processor_path = os.path.join(self.save_dir, 'processor')\n        \n        torch.save({\n            'epoch': epoch,\n            'global_step': self.global_step,\n            'model_state_dict': self.model.state_dict(),\n            'optimizer_state_dict': self.optimizer.state_dict(),\n            'train_losses': self.train_losses,\n            'eval_losses': self.eval_losses,\n            'eval_wers': self.eval_wers,\n            'train_eval_losses': self.train_eval_losses,\n            'train_eval_wers': self.train_eval_wers,\n            'learning_rate_values': self.learning_rate_values,\n            'learning_rate': self.learning_rate,\n            'weight_decay': self.weight_decay,\n            'scheduler_state_dict': self.scheduler.state_dict(),\n            'num_train_epochs': self.num_train_epochs, \n            'train_batch_size': self.train_batch_size, \n            'gradient_accumulation_steps': self.gradient_accumulation_steps,\n            'save_steps': self.save_steps,  \n            'logging_steps': self.logging_steps, \n            'warmup_steps': self.warmup_steps,\n            'seed': self.seed,  # Lưu trữ seed\n        }, checkpoint_path)\n\n        self.processor.save_pretrained(processor_path)\n        print(f\"Checkpoint saved at {checkpoint_path}, step: {self.global_step}/{self.total_steps}\")\n\n    def load_checkpoint(self):\n        checkpoints = [f for f in os.listdir(self.checkpoint_dir) if f.startswith('checkpoint_epoch_')]\n        if checkpoints:\n            latest_checkpoint = max(checkpoints, key=lambda x: int(x.split('_')[-1].split(\".\")[0]))\n            checkpoint_path = os.path.join(self.checkpoint_dir, latest_checkpoint)\n            processor_path = os.path.join(self.checkpoint_dir, 'processor')\n            \n            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n            self.model.load_state_dict(checkpoint['model_state_dict'])\n            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n\n            self.start_epoch = checkpoint['epoch']\n            self.global_step = checkpoint['global_step']\n            self.learning_rate = checkpoint['learning_rate']\n            self.weight_decay = checkpoint['weight_decay']\n            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n            self.num_train_epochs = checkpoint['num_train_epochs']\n            self.train_batch_size = checkpoint['train_batch_size']\n            self.gradient_accumulation_steps = checkpoint['gradient_accumulation_steps']\n            self.save_steps = checkpoint['save_steps']\n            self.logging_steps = checkpoint['logging_steps']\n            self.warmup_steps = checkpoint['warmup_steps']\n            self.seed = checkpoint.get('seed', self.seed)  # Lấy seed từ checkpoint nếu có\n\n            self.train_losses = checkpoint['train_losses']\n            self.eval_losses = checkpoint['eval_losses']\n            self.eval_wers = checkpoint['eval_wers']\n            self.train_eval_losses = checkpoint['train_eval_losses']\n            self.train_eval_wers = checkpoint['train_eval_wers']\n            self.learning_rate_values = checkpoint['learning_rate_values']\n\n            self.processor = Wav2Vec2Processor.from_pretrained(processor_path)\n            print(f\"Resumed from checkpoint at epoch {self.start_epoch}, global step {self.global_step}\")","metadata":{"_uuid":"4d3f444a-456b-44b9-a940-07b7b7b77488","_cell_guid":"06791fc7-399e-461c-85fd-06f3a77d482a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Đóng băng tầng feature extractor\nmodel.freeze_feature_encoder()\n\ntrainer = MyTrainer(\n    model=model,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    processor=processor,\n    data_collator=data_collator,\n    learning_rate=1e-4, \n    num_train_epochs=15,\n    train_batch_size=4,\n    gradient_accumulation_steps=2,\n    seed=42  # Đặt seed này\n)","metadata":{"_uuid":"74fd592a-d33b-401e-bf26-bd0ae7af0772","_cell_guid":"6f6e75ae-3217-40f1-9200-9767241ab20f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bắt đầu huấn luyện\ntrainer.train()","metadata":{"_uuid":"a5edaec9-aa6f-4d1d-adab-e737db99ac56","_cell_guid":"332e4217-4425-4919-a84c-b8ef2ae80004","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = range(1, len(trainer.train_losses) + 1)\n\nplt.figure(figsize=(12, 4))\n\n# Vẽ train loss và eval loss\nplt.subplot(1, 2, 1)\nplt.plot(epochs, trainer.train_losses, label='Train Loss')\nplt.plot(epochs, trainer.eval_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Loss over Epochs')\nplt.legend()\n\n# Vẽ WER\nplt.subplot(1, 2, 2)\nplt.plot(epochs, trainer.eval_wers, label='Validation WER')\nplt.xlabel('Epoch')\nplt.ylabel('WER')\nplt.title('WER over Epochs')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vẽ train learning rate\nplt.figure()\nplt.plot(range(1, len(trainer.learning_rate_values) + 1), trainer.learning_rate_values)\nplt.xlabel('Step')\nplt.ylabel('Learning Rate')\nplt.title('Learning Rate over Steps')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Đánh giá mô hình trên tập huấn luyện\ntrain_loss, train_wer = trainer.evaluate(dataset=train_dataset, description=\"Evaluating on Train Dataset\")\nprint(f\"Final Train Loss: {train_loss:.4f}, Final Train WER: {train_wer:.4f}\")\n\n# Đánh giá mô hình trên tập kiểm tra\ntest_loss, test_wer = trainer.evaluate(dataset=test_dataset, description=\"Evaluating on Test Dataset\")\nprint(f\"Final Test Loss: {test_loss:.4f}, Final Test WER: {test_wer:.4f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hiển thị một số mẫu dự đoán trên tập kiểm tra\ndef display_predictions(predictions, references, num_samples=5):\n    print(\"Sample Predictions:\")\n    for i in range(num_samples):\n        print(f\"Reference[{i}]: {references[i]}\")\n        print(f\"Prediction[{i}]: {predictions[i]}\")\n        print(\"-\" * 50)\n\n# Lấy dự đoán trên tập kiểm tra\ndef get_predictions(model, processor, dataset, data_collator, device):\n    model.eval()\n    loader = DataLoader(dataset, batch_size=1, collate_fn=data_collator)\n    predictions = []\n    references = []\n\n    for batch in loader:\n        inputs = batch['input_values'].to(device)\n        labels = batch['labels'].to(device)\n        with torch.no_grad():\n            outputs = model(inputs, labels=labels)\n        # Lấy dự đoán\n        logits = outputs.logits\n        pred_ids = torch.argmax(logits, dim=-1)\n        pred_str = processor.batch_decode(pred_ids)\n        \n        # Lấy nhãn thực\n        label_ids = labels.cpu().numpy()\n        label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n        label_str = processor.batch_decode(label_ids, group_tokens=False)\n        \n        predictions.extend(pred_str)\n        references.extend(label_str)\n\n    model.train()\n    return predictions, references","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions, test_references = get_predictions(trainer.model, trainer.processor, test_dataset, data_collator, trainer.device)\n# Hiển thị 5 mẫu dự đoán\ndisplay_predictions(test_predictions, test_references, num_samples=5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Thử nghiệm trên một tệp âm thanh từ tập kiểm tra\n# def transcribe_sample(sample, model, processor, device):\n#     # Lấy giá trị input và nhãn\n#     input_values = sample[\"input_values\"]\n#     label_ids = sample[\"labels\"]\n\n#     # Giải mã nhãn để lấy văn bản tham chiếu\n#     label_ids = np.array(label_ids)\n#     label_ids[label_ids == -100] = processor.tokenizer.pad_token_id  # Thay -100 bằng giá trị PAD\n#     reference_text = processor.batch_decode(label_ids, group_tokens=False)[0]\n\n#     # Chuyển đổi thành tensor và đưa vào thiết bị\n#     input_tensor = torch.tensor(input_values).unsqueeze(0).to(device)\n\n#     # Dự đoán\n#     with torch.no_grad():\n#         logits = model(input_tensor).logits\n\n#     # Lấy dự đoán\n#     pred_ids = torch.argmax(logits, dim=-1)\n#     pred_str = processor.batch_decode(pred_ids)[0]\n\n#     print(\"Reference:\", reference_text)\n#     print(\"Prediction:\", pred_str)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Thử nghiệm trên một tệp âm thanh tùy ý (nếu có thoi, ko thi thoi)\n# def transcribe_audio_file(audio_file_path, model, processor, device):\n#     # Đọc tệp âm thanh\n#     speech_array, sampling_rate = torchaudio.load(audio_file_path)\n#     resampler = torchaudio.transforms.Resample(orig_freq=sampling_rate, new_freq=16000)\n#     speech = resampler(speech_array).squeeze().numpy()\n    \n#     # Xử lý âm thanh\n#     input_values = processor(speech, sampling_rate=16000).input_values[0]\n#     input_tensor = torch.tensor(input_values).unsqueeze(0).to(device)\n    \n#     # Dự đoán\n#     with torch.no_grad():\n#         logits = model(input_tensor).logits\n    \n#     # Lấy dự đoán\n#     pred_ids = torch.argmax(logits, dim=-1)\n#     pred_str = processor.batch_decode(pred_ids)[0]\n    \n#     return pred_str","metadata":{},"execution_count":null,"outputs":[]}]}