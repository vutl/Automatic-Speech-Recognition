{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.602194787379972,
  "eval_steps": 500,
  "global_step": 7000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.13717421124828533,
      "grad_norm": 3891639.5,
      "learning_rate": 2e-05,
      "loss": 32.6888,
      "step": 100
    },
    {
      "epoch": 0.27434842249657065,
      "grad_norm": 859427.625,
      "learning_rate": 4e-05,
      "loss": 13.5348,
      "step": 200
    },
    {
      "epoch": 0.411522633744856,
      "grad_norm": 139306.859375,
      "learning_rate": 6e-05,
      "loss": 7.5076,
      "step": 300
    },
    {
      "epoch": 0.5486968449931413,
      "grad_norm": 231672.109375,
      "learning_rate": 8e-05,
      "loss": 7.0013,
      "step": 400
    },
    {
      "epoch": 0.6858710562414266,
      "grad_norm": 127073.3828125,
      "learning_rate": 0.0001,
      "loss": 6.9237,
      "step": 500
    },
    {
      "epoch": 0.6858710562414266,
      "eval_loss": 3.4644100666046143,
      "eval_runtime": 52.2664,
      "eval_samples_per_second": 14.541,
      "eval_steps_per_second": 0.918,
      "eval_wer": 1.0,
      "step": 500
    },
    {
      "epoch": 0.823045267489712,
      "grad_norm": 106608.09375,
      "learning_rate": 9.852724594992637e-05,
      "loss": 6.8512,
      "step": 600
    },
    {
      "epoch": 0.9602194787379973,
      "grad_norm": 114086.0234375,
      "learning_rate": 9.705449189985273e-05,
      "loss": 6.5892,
      "step": 700
    },
    {
      "epoch": 1.0973936899862826,
      "grad_norm": 142048.78125,
      "learning_rate": 9.55817378497791e-05,
      "loss": 4.444,
      "step": 800
    },
    {
      "epoch": 1.2345679012345678,
      "grad_norm": 120787.609375,
      "learning_rate": 9.410898379970545e-05,
      "loss": 2.8872,
      "step": 900
    },
    {
      "epoch": 1.3717421124828533,
      "grad_norm": 180668.609375,
      "learning_rate": 9.263622974963182e-05,
      "loss": 2.2131,
      "step": 1000
    },
    {
      "epoch": 1.3717421124828533,
      "eval_loss": 0.7370249032974243,
      "eval_runtime": 52.6819,
      "eval_samples_per_second": 14.426,
      "eval_steps_per_second": 0.911,
      "eval_wer": 0.5878010878010878,
      "step": 1000
    },
    {
      "epoch": 1.5089163237311385,
      "grad_norm": 151264.734375,
      "learning_rate": 9.116347569955818e-05,
      "loss": 1.8954,
      "step": 1100
    },
    {
      "epoch": 1.646090534979424,
      "grad_norm": 180964.5,
      "learning_rate": 8.969072164948454e-05,
      "loss": 1.7305,
      "step": 1200
    },
    {
      "epoch": 1.7832647462277091,
      "grad_norm": 168330.5,
      "learning_rate": 8.82179675994109e-05,
      "loss": 1.6179,
      "step": 1300
    },
    {
      "epoch": 1.9204389574759944,
      "grad_norm": 187970.40625,
      "learning_rate": 8.674521354933727e-05,
      "loss": 1.4658,
      "step": 1400
    },
    {
      "epoch": 2.05761316872428,
      "grad_norm": 206844.09375,
      "learning_rate": 8.527245949926362e-05,
      "loss": 1.3656,
      "step": 1500
    },
    {
      "epoch": 2.05761316872428,
      "eval_loss": 0.5032930374145508,
      "eval_runtime": 52.6034,
      "eval_samples_per_second": 14.448,
      "eval_steps_per_second": 0.912,
      "eval_wer": 0.42126392126392126,
      "step": 1500
    },
    {
      "epoch": 2.1947873799725652,
      "grad_norm": 186115.578125,
      "learning_rate": 8.379970544918999e-05,
      "loss": 1.3,
      "step": 1600
    },
    {
      "epoch": 2.3319615912208507,
      "grad_norm": 182049.5,
      "learning_rate": 8.232695139911635e-05,
      "loss": 1.2865,
      "step": 1700
    },
    {
      "epoch": 2.4691358024691357,
      "grad_norm": 579037.0,
      "learning_rate": 8.085419734904272e-05,
      "loss": 1.2455,
      "step": 1800
    },
    {
      "epoch": 2.606310013717421,
      "grad_norm": 228593.078125,
      "learning_rate": 7.938144329896907e-05,
      "loss": 1.1921,
      "step": 1900
    },
    {
      "epoch": 2.7434842249657065,
      "grad_norm": 1007382.8125,
      "learning_rate": 7.790868924889544e-05,
      "loss": 1.1905,
      "step": 2000
    },
    {
      "epoch": 2.7434842249657065,
      "eval_loss": 0.44475257396698,
      "eval_runtime": 53.4152,
      "eval_samples_per_second": 14.228,
      "eval_steps_per_second": 0.899,
      "eval_wer": 0.3736078736078736,
      "step": 2000
    },
    {
      "epoch": 2.8806584362139915,
      "grad_norm": 347621.03125,
      "learning_rate": 7.64359351988218e-05,
      "loss": 1.156,
      "step": 2100
    },
    {
      "epoch": 3.017832647462277,
      "grad_norm": 98177.859375,
      "learning_rate": 7.496318114874816e-05,
      "loss": 1.1279,
      "step": 2200
    },
    {
      "epoch": 3.1550068587105624,
      "grad_norm": 159299.1875,
      "learning_rate": 7.349042709867453e-05,
      "loss": 1.0296,
      "step": 2300
    },
    {
      "epoch": 3.292181069958848,
      "grad_norm": 106324.828125,
      "learning_rate": 7.201767304860089e-05,
      "loss": 1.0476,
      "step": 2400
    },
    {
      "epoch": 3.4293552812071333,
      "grad_norm": 119379.65625,
      "learning_rate": 7.054491899852726e-05,
      "loss": 1.002,
      "step": 2500
    },
    {
      "epoch": 3.4293552812071333,
      "eval_loss": 0.39611920714378357,
      "eval_runtime": 52.3996,
      "eval_samples_per_second": 14.504,
      "eval_steps_per_second": 0.916,
      "eval_wer": 0.3256928256928257,
      "step": 2500
    },
    {
      "epoch": 3.5665294924554183,
      "grad_norm": 176367.296875,
      "learning_rate": 6.907216494845361e-05,
      "loss": 1.0254,
      "step": 2600
    },
    {
      "epoch": 3.7037037037037037,
      "grad_norm": 79189.703125,
      "learning_rate": 6.759941089837998e-05,
      "loss": 0.9854,
      "step": 2700
    },
    {
      "epoch": 3.840877914951989,
      "grad_norm": 105217.765625,
      "learning_rate": 6.612665684830633e-05,
      "loss": 1.0125,
      "step": 2800
    },
    {
      "epoch": 3.978052126200274,
      "grad_norm": 173981.40625,
      "learning_rate": 6.46539027982327e-05,
      "loss": 0.9843,
      "step": 2900
    },
    {
      "epoch": 4.11522633744856,
      "grad_norm": 179707.515625,
      "learning_rate": 6.318114874815906e-05,
      "loss": 0.9303,
      "step": 3000
    },
    {
      "epoch": 4.11522633744856,
      "eval_loss": 0.38099461793899536,
      "eval_runtime": 52.3167,
      "eval_samples_per_second": 14.527,
      "eval_steps_per_second": 0.917,
      "eval_wer": 0.3023828023828024,
      "step": 3000
    },
    {
      "epoch": 4.252400548696845,
      "grad_norm": 132637.671875,
      "learning_rate": 6.170839469808543e-05,
      "loss": 0.9204,
      "step": 3100
    },
    {
      "epoch": 4.3895747599451305,
      "grad_norm": 167579.859375,
      "learning_rate": 6.023564064801178e-05,
      "loss": 0.9336,
      "step": 3200
    },
    {
      "epoch": 4.526748971193416,
      "grad_norm": 128358.5078125,
      "learning_rate": 5.876288659793815e-05,
      "loss": 0.9124,
      "step": 3300
    },
    {
      "epoch": 4.663923182441701,
      "grad_norm": 185066.8125,
      "learning_rate": 5.7290132547864505e-05,
      "loss": 0.8724,
      "step": 3400
    },
    {
      "epoch": 4.801097393689986,
      "grad_norm": 147084.859375,
      "learning_rate": 5.5817378497790873e-05,
      "loss": 0.88,
      "step": 3500
    },
    {
      "epoch": 4.801097393689986,
      "eval_loss": 0.3728387951850891,
      "eval_runtime": 53.1376,
      "eval_samples_per_second": 14.302,
      "eval_steps_per_second": 0.903,
      "eval_wer": 0.29241129241129243,
      "step": 3500
    },
    {
      "epoch": 4.938271604938271,
      "grad_norm": 466900.15625,
      "learning_rate": 5.434462444771723e-05,
      "loss": 0.8904,
      "step": 3600
    },
    {
      "epoch": 5.075445816186557,
      "grad_norm": 116851.3671875,
      "learning_rate": 5.28718703976436e-05,
      "loss": 0.8878,
      "step": 3700
    },
    {
      "epoch": 5.212620027434842,
      "grad_norm": 197849.265625,
      "learning_rate": 5.139911634756995e-05,
      "loss": 0.8756,
      "step": 3800
    },
    {
      "epoch": 5.349794238683128,
      "grad_norm": 137087.203125,
      "learning_rate": 4.992636229749632e-05,
      "loss": 0.8639,
      "step": 3900
    },
    {
      "epoch": 5.486968449931413,
      "grad_norm": 73159.453125,
      "learning_rate": 4.845360824742268e-05,
      "loss": 0.8301,
      "step": 4000
    },
    {
      "epoch": 5.486968449931413,
      "eval_loss": 0.3632429540157318,
      "eval_runtime": 52.0782,
      "eval_samples_per_second": 14.593,
      "eval_steps_per_second": 0.922,
      "eval_wer": 0.2779072779072779,
      "step": 4000
    },
    {
      "epoch": 5.6241426611796985,
      "grad_norm": 82383.3671875,
      "learning_rate": 4.6980854197349045e-05,
      "loss": 0.8347,
      "step": 4100
    },
    {
      "epoch": 5.761316872427983,
      "grad_norm": 76083.46875,
      "learning_rate": 4.5508100147275406e-05,
      "loss": 0.8357,
      "step": 4200
    },
    {
      "epoch": 5.8984910836762685,
      "grad_norm": 384343.09375,
      "learning_rate": 4.403534609720177e-05,
      "loss": 0.8213,
      "step": 4300
    },
    {
      "epoch": 6.035665294924554,
      "grad_norm": 465695.34375,
      "learning_rate": 4.256259204712813e-05,
      "loss": 0.7931,
      "step": 4400
    },
    {
      "epoch": 6.172839506172839,
      "grad_norm": 96702.6015625,
      "learning_rate": 4.108983799705449e-05,
      "loss": 0.7781,
      "step": 4500
    },
    {
      "epoch": 6.172839506172839,
      "eval_loss": 0.3503311276435852,
      "eval_runtime": 52.2417,
      "eval_samples_per_second": 14.548,
      "eval_steps_per_second": 0.919,
      "eval_wer": 0.27143227143227144,
      "step": 4500
    },
    {
      "epoch": 6.310013717421125,
      "grad_norm": 106814.4453125,
      "learning_rate": 3.9617083946980854e-05,
      "loss": 0.7867,
      "step": 4600
    },
    {
      "epoch": 6.44718792866941,
      "grad_norm": 103461.0234375,
      "learning_rate": 3.8144329896907216e-05,
      "loss": 0.808,
      "step": 4700
    },
    {
      "epoch": 6.584362139917696,
      "grad_norm": 87220.40625,
      "learning_rate": 3.667157584683358e-05,
      "loss": 0.7943,
      "step": 4800
    },
    {
      "epoch": 6.721536351165981,
      "grad_norm": 137858.9375,
      "learning_rate": 3.5198821796759946e-05,
      "loss": 0.78,
      "step": 4900
    },
    {
      "epoch": 6.858710562414267,
      "grad_norm": 92432.765625,
      "learning_rate": 3.372606774668631e-05,
      "loss": 0.7237,
      "step": 5000
    },
    {
      "epoch": 6.858710562414267,
      "eval_loss": 0.33613350987434387,
      "eval_runtime": 52.4922,
      "eval_samples_per_second": 14.478,
      "eval_steps_per_second": 0.914,
      "eval_wer": 0.2562807562807563,
      "step": 5000
    },
    {
      "epoch": 6.995884773662551,
      "grad_norm": 233907.4375,
      "learning_rate": 3.225331369661267e-05,
      "loss": 0.7688,
      "step": 5100
    },
    {
      "epoch": 7.133058984910837,
      "grad_norm": 309923.65625,
      "learning_rate": 3.078055964653903e-05,
      "loss": 0.732,
      "step": 5200
    },
    {
      "epoch": 7.270233196159122,
      "grad_norm": 181190.859375,
      "learning_rate": 2.9307805596465393e-05,
      "loss": 0.7287,
      "step": 5300
    },
    {
      "epoch": 7.407407407407407,
      "grad_norm": 179425.078125,
      "learning_rate": 2.7835051546391755e-05,
      "loss": 0.7529,
      "step": 5400
    },
    {
      "epoch": 7.544581618655693,
      "grad_norm": 237735.625,
      "learning_rate": 2.6362297496318117e-05,
      "loss": 0.7497,
      "step": 5500
    },
    {
      "epoch": 7.544581618655693,
      "eval_loss": 0.34662219882011414,
      "eval_runtime": 52.3431,
      "eval_samples_per_second": 14.52,
      "eval_steps_per_second": 0.917,
      "eval_wer": 0.26081326081326084,
      "step": 5500
    },
    {
      "epoch": 7.681755829903978,
      "grad_norm": 260414.9375,
      "learning_rate": 2.488954344624448e-05,
      "loss": 0.7206,
      "step": 5600
    },
    {
      "epoch": 7.818930041152264,
      "grad_norm": 223351.5625,
      "learning_rate": 2.341678939617084e-05,
      "loss": 0.7541,
      "step": 5700
    },
    {
      "epoch": 7.956104252400548,
      "grad_norm": 502839.59375,
      "learning_rate": 2.1944035346097203e-05,
      "loss": 0.7237,
      "step": 5800
    },
    {
      "epoch": 8.093278463648835,
      "grad_norm": 123990.203125,
      "learning_rate": 2.0471281296023564e-05,
      "loss": 0.7074,
      "step": 5900
    },
    {
      "epoch": 8.23045267489712,
      "grad_norm": 93588.109375,
      "learning_rate": 1.8998527245949926e-05,
      "loss": 0.6972,
      "step": 6000
    },
    {
      "epoch": 8.23045267489712,
      "eval_loss": 0.3388406038284302,
      "eval_runtime": 53.3503,
      "eval_samples_per_second": 14.245,
      "eval_steps_per_second": 0.9,
      "eval_wer": 0.2498057498057498,
      "step": 6000
    },
    {
      "epoch": 8.367626886145406,
      "grad_norm": 106458.4765625,
      "learning_rate": 1.7525773195876288e-05,
      "loss": 0.6782,
      "step": 6100
    },
    {
      "epoch": 8.50480109739369,
      "grad_norm": 77701.8125,
      "learning_rate": 1.6053019145802653e-05,
      "loss": 0.7222,
      "step": 6200
    },
    {
      "epoch": 8.641975308641975,
      "grad_norm": 102556.34375,
      "learning_rate": 1.4580265095729015e-05,
      "loss": 0.6981,
      "step": 6300
    },
    {
      "epoch": 8.779149519890261,
      "grad_norm": 850211.0625,
      "learning_rate": 1.3107511045655377e-05,
      "loss": 0.7207,
      "step": 6400
    },
    {
      "epoch": 8.916323731138545,
      "grad_norm": 3228156.5,
      "learning_rate": 1.1634756995581739e-05,
      "loss": 0.6912,
      "step": 6500
    },
    {
      "epoch": 8.916323731138545,
      "eval_loss": 0.32928287982940674,
      "eval_runtime": 52.425,
      "eval_samples_per_second": 14.497,
      "eval_steps_per_second": 0.916,
      "eval_wer": 0.24281274281274282,
      "step": 6500
    },
    {
      "epoch": 9.053497942386832,
      "grad_norm": 102367.390625,
      "learning_rate": 1.01620029455081e-05,
      "loss": 0.705,
      "step": 6600
    },
    {
      "epoch": 9.190672153635116,
      "grad_norm": 144213.140625,
      "learning_rate": 8.689248895434462e-06,
      "loss": 0.6807,
      "step": 6700
    },
    {
      "epoch": 9.327846364883403,
      "grad_norm": 198045.25,
      "learning_rate": 7.216494845360824e-06,
      "loss": 0.675,
      "step": 6800
    },
    {
      "epoch": 9.465020576131687,
      "grad_norm": 241981.953125,
      "learning_rate": 5.743740795287187e-06,
      "loss": 0.699,
      "step": 6900
    },
    {
      "epoch": 9.602194787379972,
      "grad_norm": 153812.109375,
      "learning_rate": 4.27098674521355e-06,
      "loss": 0.6999,
      "step": 7000
    },
    {
      "epoch": 9.602194787379972,
      "eval_loss": 0.32858729362487793,
      "eval_runtime": 52.2933,
      "eval_samples_per_second": 14.533,
      "eval_steps_per_second": 0.918,
      "eval_wer": 0.24333074333074334,
      "step": 7000
    }
  ],
  "logging_steps": 100,
  "max_steps": 7290,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.587858266667293e+19,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
